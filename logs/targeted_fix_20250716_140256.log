[14:02:56] ðŸ”¥ Setting up GPU configuration...
[14:02:56] ðŸŽ¯ Using device: cuda:0
[14:02:56] ðŸ“¦ Loading RAG models...
[14:06:07] ðŸš€ RAG system ready!
[14:06:07] ðŸ“š Loading targeted evaluation dataset...
[14:06:12] ðŸ“Š Dataset loaded: 50 questions
[14:06:12]    - SQuAD questions: 91
[14:06:12] ðŸ§ª Starting targeted RAG experiment...
[14:06:12] ðŸ“‹ Testing 7 templates on 50 questions
[14:06:12] 
ðŸ”„ Testing template: retrieval_focused
[14:06:13] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:13] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:13] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='paris'
[14:06:13] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:13] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:14] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:14] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:14] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='william shakespeare'
[14:06:14] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:14] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:14] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:14] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:14] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='4'
[14:06:14] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:14] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:14] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:14] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:14] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='process where plants make food from sunlight'
[14:06:14] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:14] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:14] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:14] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:14] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='they process information using electrical circuits'
[14:06:14] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:14] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:14] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:14] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:14] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='red blue green'
[14:06:14] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:14] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:15] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:15] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:15] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='cat dog'
[14:06:15] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:15] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:15] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:15] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:15] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='essential for life and survival'
[14:06:15] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:15] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:15] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:15] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:15] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='chlorophyll'
[14:06:15] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:15] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:15] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:15] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:15] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='yes'
[14:06:15] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:15] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:15]   Progress: 10/50 - Recent F1: 0.000
[14:06:15] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:15] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:15] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='yes'
[14:06:15] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:15] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:16] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:16] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:16] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='red yellow blue'
[14:06:16] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:16] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:16] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:16] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:16] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='france'
[14:06:16] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:16] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:16] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:16] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:16] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='10th and 11th centuries'
[14:06:16] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:16] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:16] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:16] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:16] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='denmark, iceland and norway'
[14:06:16] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:16] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:16] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:16] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:16] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='rollo'
[14:06:16] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:16] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:17] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:17] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:17] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='10th century'
[14:06:17] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:17] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:17] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:17] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:17] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='william the conqueror'
[14:06:17] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:17] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:17] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:17] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:17] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='richard i'
[14:06:17] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:17] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:17] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:17] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:17] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='catholic'
[14:06:17] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:17] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:17]   Progress: 20/50 - Recent F1: 0.000
[14:06:17] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:17] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:17] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='viking'
[14:06:17] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:17] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:18] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:18] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:18] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='9th century'
[14:06:18] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:18] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:18] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:18] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:18] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='911'
[14:06:18] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:18] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:18] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:18] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:18] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='king charles iii'
[14:06:18] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:18] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:18] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:18] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:18] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='seine'
[14:06:18] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:18] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:18] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:18] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:18] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='rollo'
[14:06:18] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:18] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:19] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:19] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 70.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:19] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='catholicism'
[14:06:19] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:19] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:19] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:19] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:19] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='north'
[14:06:19] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:19] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:19] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:19] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:19] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='fighting horsemen'
[14:06:19] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:19] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:19] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:19] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:19] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='seljuk turks'
[14:06:19] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:19] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:19]   Progress: 30/50 - Recent F1: 0.000
[14:06:19] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:19] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:19] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='1050s'
[14:06:19] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:19] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:19] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:19] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:19] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='1060s'
[14:06:19] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:19] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:20] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:20] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:20] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='alexius komnenos'
[14:06:20] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:20] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:20] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:20] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:20] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='afranji'
[14:06:20] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:20] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:20] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:20] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:20] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='oursel'
[14:06:20] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:20] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:20] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:20] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:20] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='turkish forces'
[14:06:20] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:20] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:20] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:20] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:20] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='norman mercenary'
[14:06:20] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:20] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:21] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:21] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:21] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='robert guiscard'
[14:06:21] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:21] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:21] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:21] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3068, in beam_search
    outputs = self(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1318, in forward
    outputs = self.rag(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 677, in forward
    gen_outputs = self.generator(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1731, in forward
    outputs = self.model(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1617, in forward
    decoder_outputs = self.decoder(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 1470, in forward
    layer_outputs = decoder_layer(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 779, in forward
    hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 563, in forward
    key_states = self._shape(self.k_proj(key_value_states), -1, bsz)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py", line 173, in _shape
    return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 558.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 2.77 GiB memory in use. Process 1085896 has 2.60 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 69.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:21] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='1082'
[14:06:21] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:21] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:21] Generation error for retrieval_focused: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 552.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 3.46 GiB memory in use. Process 1085896 has 1.92 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 72.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[14:06:21] Full traceback: Traceback (most recent call last):
  File "/home/iqra.bano/Dissertation/project/production_rag_experiment/scripts/enhanced.py", line 263, in generate_answer
    generated = self.model.generate(input_ids=input_ids)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1562, in generate
    return self.beam_search(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 3143, in beam_search
    model_kwargs["past_key_values"] = self._temporary_reorder_cache(
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/generation/utils.py", line 2805, in _temporary_reorder_cache
    past_key_values = self._reorder_cache(past_key_values, beam_idx)
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1214, in _reorder_cache
    tuple(_reorder_stacked(past_state, beam_idx.to(past_state.device)) for past_state in layer_past),
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1214, in <genexpr>
    tuple(_reorder_stacked(past_state, beam_idx.to(past_state.device)) for past_state in layer_past),
  File "/home/iqra.bano/.conda/envs/dissertation_env/lib/python3.10/site-packages/transformers/models/rag/modeling_rag.py", line 1206, in _reorder_stacked
    hidden_states = hidden_states.index_select(0, new_order)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 552.56 MiB is free. Process 107363 has 19.91 GiB memory in use. Process 107438 has 2.89 GiB memory in use. Process 544574 has 2.56 GiB memory in use. Process 600986 has 28.69 GiB memory in use. Process 1052789 has 8.83 GiB memory in use. Process 1053083 has 10.30 GiB memory in use. Including non-PyTorch memory, this process has 3.46 GiB memory in use. Process 1085896 has 1.92 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 72.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[14:06:21] DEBUG: Generated='generation error: cuda out of memory. tried to allocate 24.00 mib. g' vs Expected='30,000'
[14:06:21] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:21] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:21]   Progress: 40/50 - Recent F1: 0.000
[14:06:22] DEBUG: Generated='constantinople' vs Expected='deabolis'
[14:06:22] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:22] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:22] DEBUG: Generated='robert's son' vs Expected='bohemond'
[14:06:22] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:22] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:23] DEBUG: Generated='river sita' vs Expected='deabolis'
[14:06:23] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:23] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:23] DEBUG: Generated='2003' vs Expected='1185'
[14:06:23] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:23] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:24] DEBUG: Generated='naval station guantanamo bay' vs Expected='dyrrachium'
[14:06:24] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:24] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:24] DEBUG: Generated='north - western asia' vs Expected='the adriatic'
[14:06:24] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:24] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:25] DEBUG: Generated='matt willis' vs Expected='king ethelred ii'
[14:06:25] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:25] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:26] DEBUG: Generated='bryce gheisar' vs Expected='duke richard ii'
[14:06:26] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:26] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:26] DEBUG: Generated='britain' vs Expected='normandy'
[14:06:26] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:26] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:27] DEBUG: Generated='the undertaker' vs Expected='sweyn forkbeard'
[14:06:27] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:27] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:27]   Progress: 50/50 - Recent F1: 0.000
[14:06:27]    retrieval_focused completed: F1=0.000, EM=0.000
[14:06:27] 
ðŸ”„ Testing template: knowledge_synthesis
[14:06:27] DEBUG: Generated='paris' vs Expected='paris'
[14:06:27] DEBUG: Overlap=1, Precision=1.000, Recall=1.000
[14:06:27] DEBUG: F1=1.000, EM=1.0, Overlap=1.000
[14:06:28] DEBUG: Generated='who?' vs Expected='william shakespeare'
[14:06:28] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:28] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:28] DEBUG: Generated='factorials n!' vs Expected='4'
[14:06:28] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:28] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:29] DEBUG: Generated='plants, algae and cyanobacteria' vs Expected='process where plants make food from sunlight'
[14:06:29] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:29] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:30] DEBUG: Generated='problem / problem / solution' vs Expected='they process information using electrical circuits'
[14:06:30] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:30] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:30] DEBUG: Generated='' vs Expected='red blue green'
[14:06:30] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:30] DEBUG: Generated='cat' vs Expected='cat dog'
[14:06:30] DEBUG: Overlap=1, Precision=1.000, Recall=0.500
[14:06:30] DEBUG: F1=0.667, EM=0.0, Overlap=0.500
[14:06:31] DEBUG: Generated='data visuali zation' vs Expected='essential for life and survival'
[14:06:31] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:31] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:31] DEBUG: Generated='what makes plants green' vs Expected='chlorophyll'
[14:06:31] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:31] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:32] DEBUG: Generated='what turns you on?' vs Expected='yes'
[14:06:32] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:32] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:32]   Progress: 10/50 - Recent F1: 0.167
[14:06:32] DEBUG: Generated='do you like sex?' vs Expected='yes'
[14:06:32] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:32] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:33] DEBUG: Generated='blue' vs Expected='red yellow blue'
[14:06:33] DEBUG: Overlap=1, Precision=1.000, Recall=0.333
[14:06:33] DEBUG: F1=0.500, EM=0.0, Overlap=0.333
[14:06:33] DEBUG: Generated='france' vs Expected='france'
[14:06:33] DEBUG: Overlap=1, Precision=1.000, Recall=1.000
[14:06:33] DEBUG: F1=1.000, EM=1.0, Overlap=1.000
[14:06:34] DEBUG: Generated='10th century -- 15th century' vs Expected='10th and 11th centuries'
[14:06:34] DEBUG: Overlap=1, Precision=0.250, Recall=0.250
[14:06:34] DEBUG: F1=0.250, EM=0.0, Overlap=0.250
[14:06:34] DEBUG: Generated='scandinavia' vs Expected='denmark, iceland and norway'
[14:06:34] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:34] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:35] DEBUG: Generated='who was the norse leader' vs Expected='rollo'
[14:06:35] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:35] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:35] DEBUG: Generated='the ninth century' vs Expected='10th century'
[14:06:35] DEBUG: Overlap=1, Precision=0.333, Recall=0.500
[14:06:35] DEBUG: F1=0.400, EM=0.0, Overlap=0.500
[14:06:36] DEBUG: Generated='normandy duke of normandy' vs Expected='william the conqueror'
[14:06:36] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:36] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:37] DEBUG: Generated='king charles iii' vs Expected='richard i'
[14:06:37] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:37] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:37] DEBUG: Generated='catholicism' vs Expected='catholic'
[14:06:37] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:37] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:37]   Progress: 20/50 - Recent F1: 0.215
[14:06:38] DEBUG: Generated='data visuali zation' vs Expected='viking'
[14:06:38] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:38] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:38] DEBUG: Generated='in 1024' vs Expected='9th century'
[14:06:38] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:38] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:39] DEBUG: Generated='1066' vs Expected='911'
[14:06:39] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:39] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:39] DEBUG: Generated='patrick alexander russell' vs Expected='king charles iii'
[14:06:39] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:39] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:40] DEBUG: Generated='tennessee river' vs Expected='seine'
[14:06:40] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:40] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:40] DEBUG: Generated='the normans' vs Expected='rollo'
[14:06:40] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:40] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:41] DEBUG: Generated='islam' vs Expected='catholicism'
[14:06:41] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:41] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:41] DEBUG: Generated='normandy' vs Expected='north'
[14:06:41] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:41] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:42] DEBUG: Generated='266,827' vs Expected='fighting horsemen'
[14:06:42] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:42] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:42] DEBUG: Generated='byzantine empire' vs Expected='seljuk turks'
[14:06:42] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:42] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:42]   Progress: 30/50 - Recent F1: 0.000
[14:06:43] DEBUG: Generated='1984 -- 86' vs Expected='1050s'
[14:06:43] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:43] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:43] DEBUG: Generated='robert crispin's diary' vs Expected='1060s'
[14:06:43] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:43] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:44] DEBUG: Generated='british empire' vs Expected='alexius komnenos'
[14:06:44] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:44] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:44] DEBUG: Generated='' vs Expected='afranji'
[14:06:44] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:45] DEBUG: Generated='2018' vs Expected='oursel'
[14:06:45] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:45] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:45] DEBUG: Generated='turkey' vs Expected='turkish forces'
[14:06:45] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:45] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:46] DEBUG: Generated='byzantine origin' vs Expected='norman mercenary'
[14:06:46] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:46] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:46] DEBUG: Generated='' vs Expected='robert guiscard'
[14:06:46] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:46] DEBUG: Generated='1970s' vs Expected='1082'
[14:06:46] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:46] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:47] DEBUG: Generated='1,250,000 men' vs Expected='30,000'
[14:06:47] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:47] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:47]   Progress: 40/50 - Recent F1: 0.000
[14:06:47] DEBUG: Generated='constantinople' vs Expected='deabolis'
[14:06:47] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:47] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:48] DEBUG: Generated='' vs Expected='bohemond'
[14:06:48] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:48] DEBUG: Generated='river sita' vs Expected='deabolis'
[14:06:48] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:48] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:49] DEBUG: Generated='2018' vs Expected='1185'
[14:06:49] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:49] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:49] DEBUG: Generated='guantanamo bay naval base' vs Expected='dyrrachium'
[14:06:49] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:49] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:50] DEBUG: Generated='the earth's crust' vs Expected='the adriatic'
[14:06:50] DEBUG: Overlap=1, Precision=0.333, Recall=0.500
[14:06:50] DEBUG: F1=0.400, EM=0.0, Overlap=0.500
[14:06:50] DEBUG: Generated='theo' vs Expected='king ethelred ii'
[14:06:50] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:50] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:51] DEBUG: Generated='madhavrao' vs Expected='duke richard ii'
[14:06:51] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:51] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:52] DEBUG: Generated='to the netherlands' vs Expected='normandy'
[14:06:52] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:52] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:52] DEBUG: Generated='ethelred' vs Expected='sweyn forkbeard'
[14:06:52] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:52] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:52]   Progress: 50/50 - Recent F1: 0.040
[14:06:52]    knowledge_synthesis completed: F1=0.084, EM=0.040
[14:06:52] 
ðŸ”„ Testing template: instructional_clear
[14:06:53] DEBUG: Generated='paris' vs Expected='paris'
[14:06:53] DEBUG: Overlap=1, Precision=1.000, Recall=1.000
[14:06:53] DEBUG: F1=1.000, EM=1.0, Overlap=1.000
[14:06:53] DEBUG: Generated='william shakespeare' vs Expected='william shakespeare'
[14:06:53] DEBUG: Overlap=2, Precision=1.000, Recall=1.000
[14:06:53] DEBUG: F1=1.000, EM=1.0, Overlap=1.000
[14:06:54] DEBUG: Generated='the question' vs Expected='4'
[14:06:54] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:54] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:54] DEBUG: Generated='photosynthesis' vs Expected='process where plants make food from sunlight'
[14:06:54] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:54] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:55] DEBUG: Generated='what turns you on?' vs Expected='they process information using electrical circuits'
[14:06:55] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:55] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:55] DEBUG: Generated='blue' vs Expected='red blue green'
[14:06:55] DEBUG: Overlap=1, Precision=1.000, Recall=0.333
[14:06:55] DEBUG: F1=0.500, EM=0.0, Overlap=0.333
[14:06:55] DEBUG: Generated='cat' vs Expected='cat dog'
[14:06:55] DEBUG: Overlap=1, Precision=1.000, Recall=0.500
[14:06:55] DEBUG: F1=0.667, EM=0.0, Overlap=0.500
[14:06:56] DEBUG: Generated='for all known forms of life' vs Expected='essential for life and survival'
[14:06:56] DEBUG: Overlap=2, Precision=0.333, Recall=0.400
[14:06:56] DEBUG: F1=0.364, EM=0.0, Overlap=0.400
[14:06:57] DEBUG: Generated='what turns you on?' vs Expected='chlorophyll'
[14:06:57] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:57] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:57] DEBUG: Generated='the question' vs Expected='yes'
[14:06:57] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:57] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:57]   Progress: 10/50 - Recent F1: 0.353
[14:06:57] DEBUG: Generated='' vs Expected='yes'
[14:06:57] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:58] DEBUG: Generated='red' vs Expected='red yellow blue'
[14:06:58] DEBUG: Overlap=1, Precision=1.000, Recall=0.333
[14:06:58] DEBUG: F1=0.500, EM=0.0, Overlap=0.333
[14:06:58] DEBUG: Generated='france' vs Expected='france'
[14:06:58] DEBUG: Overlap=1, Precision=1.000, Recall=1.000
[14:06:58] DEBUG: F1=1.000, EM=1.0, Overlap=1.000
[14:06:59] DEBUG: Generated='during the trojan war' vs Expected='10th and 11th centuries'
[14:06:59] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:06:59] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:06:59] DEBUG: Generated='iceland' vs Expected='denmark, iceland and norway'
[14:06:59] DEBUG: Overlap=1, Precision=1.000, Recall=0.250
[14:06:59] DEBUG: F1=0.400, EM=0.0, Overlap=0.250
[14:07:00] DEBUG: Generated='the question' vs Expected='rollo'
[14:07:00] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:00] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:00] DEBUG: Generated='the ninth century' vs Expected='10th century'
[14:07:00] DEBUG: Overlap=1, Precision=0.333, Recall=0.500
[14:07:00] DEBUG: F1=0.400, EM=0.0, Overlap=0.500
[14:07:01] DEBUG: Generated='the duke of normandy' vs Expected='william the conqueror'
[14:07:01] DEBUG: Overlap=1, Precision=0.250, Recall=0.333
[14:07:01] DEBUG: F1=0.286, EM=0.0, Overlap=0.333
[14:07:02] DEBUG: Generated='king charles iii' vs Expected='richard i'
[14:07:02] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:02] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:02] DEBUG: Generated='islam' vs Expected='catholic'
[14:07:02] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:02] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:02]   Progress: 20/50 - Recent F1: 0.259
[14:07:03] DEBUG: Generated='norman' vs Expected='viking'
[14:07:03] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:03] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:03] DEBUG: Generated='in 1024' vs Expected='9th century'
[14:07:03] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:03] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:04] DEBUG: Generated='1066' vs Expected='911'
[14:07:04] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:04] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:04] DEBUG: Generated='charles' vs Expected='king charles iii'
[14:07:04] DEBUG: Overlap=1, Precision=1.000, Recall=0.333
[14:07:04] DEBUG: F1=0.500, EM=0.0, Overlap=0.333
[14:07:05] DEBUG: Generated='what turns you on?' vs Expected='seine'
[14:07:05] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:05] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:05] DEBUG: Generated='the normans' vs Expected='rollo'
[14:07:05] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:05] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:06] DEBUG: Generated='what turns you on?' vs Expected='catholicism'
[14:07:06] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:06] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:06] DEBUG: Generated='normandy' vs Expected='north'
[14:07:06] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:06] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:07] DEBUG: Generated='what turns you on?' vs Expected='fighting horsemen'
[14:07:07] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:07] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:07] DEBUG: Generated='byzantine empire' vs Expected='seljuk turks'
[14:07:07] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:07] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:07]   Progress: 30/50 - Recent F1: 0.050
[14:07:08] DEBUG: Generated='602 -- 603' vs Expected='1050s'
[14:07:08] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:08] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:08] DEBUG: Generated='robert crispin and the turks' vs Expected='1060s'
[14:07:08] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:08] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:09] DEBUG: Generated='can you please provide a clear answer' vs Expected='alexius komnenos'
[14:07:09] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:09] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:10] DEBUG: Generated='what turns you on?' vs Expected='afranji'
[14:07:10] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:10] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:10] DEBUG: Generated='roosevelt' vs Expected='oursel'
[14:07:10] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:10] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:11] DEBUG: Generated='turkey' vs Expected='turkish forces'
[14:07:11] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:11] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:11] DEBUG: Generated='normandy, france' vs Expected='norman mercenary'
[14:07:11] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:11] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:11] DEBUG: Generated='lord canning' vs Expected='robert guiscard'
[14:07:11] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:11] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:12] DEBUG: Generated='what happened to dyrrachium?' vs Expected='1082'
[14:07:12] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:12] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:13] DEBUG: Generated='1,000,000' vs Expected='30,000'
[14:07:13] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:13] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:13]   Progress: 40/50 - Recent F1: 0.000
[14:07:13] DEBUG: Generated='constantinople' vs Expected='deabolis'
[14:07:13] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:13] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:14] DEBUG: Generated=', andrew' vs Expected='bohemond'
[14:07:14] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:14] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:14] DEBUG: Generated='river sitka' vs Expected='deabolis'
[14:07:14] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:14] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:15] DEBUG: Generated='2003' vs Expected='1185'
[14:07:15] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:15] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:15] DEBUG: Generated='what turns you on?' vs Expected='dyrrachium'
[14:07:15] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:15] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:16] DEBUG: Generated='what turns you on?' vs Expected='the adriatic'
[14:07:16] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:16] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:16] DEBUG: Generated='admiral horatio nelson' vs Expected='king ethelred ii'
[14:07:16] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:16] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:17] DEBUG: Generated='the question' vs Expected='duke richard ii'
[14:07:17] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:17] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:17] DEBUG: Generated='to return to england' vs Expected='normandy'
[14:07:17] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:17] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:18] DEBUG: Generated='parliament' vs Expected='sweyn forkbeard'
[14:07:18] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:18] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:18]   Progress: 50/50 - Recent F1: 0.000
[14:07:18]    instructional_clear completed: F1=0.132, EM=0.060
[14:07:18] 
ðŸ”„ Testing template: context_guided
[14:07:18] DEBUG: Generated='paris' vs Expected='paris'
[14:07:18] DEBUG: Overlap=1, Precision=1.000, Recall=1.000
[14:07:18] DEBUG: F1=1.000, EM=1.0, Overlap=1.000
[14:07:18] DEBUG: Generated='' vs Expected='william shakespeare'
[14:07:18] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:19] DEBUG: Generated='what turns you on?' vs Expected='4'
[14:07:19] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:19] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:19] DEBUG: Generated='' vs Expected='process where plants make food from sunlight'
[14:07:19] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:20] DEBUG: Generated='what turns you on?' vs Expected='they process information using electrical circuits'
[14:07:20] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:20] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:20] DEBUG: Generated='green' vs Expected='red blue green'
[14:07:20] DEBUG: Overlap=1, Precision=1.000, Recall=0.333
[14:07:20] DEBUG: F1=0.500, EM=0.0, Overlap=0.333
[14:07:20] DEBUG: Generated='cat' vs Expected='cat dog'
[14:07:20] DEBUG: Overlap=1, Precision=1.000, Recall=0.500
[14:07:20] DEBUG: F1=0.667, EM=0.0, Overlap=0.500
[14:07:21] DEBUG: Generated='why is water important?' vs Expected='essential for life and survival'
[14:07:21] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:21] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:22] DEBUG: Generated='what makes plants green' vs Expected='chlorophyll'
[14:07:22] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:22] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:22] DEBUG: Generated='what turns you on?' vs Expected='yes'
[14:07:22] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:22] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:22]   Progress: 10/50 - Recent F1: 0.217
[14:07:23] DEBUG: Generated='the basic question' vs Expected='yes'
[14:07:23] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:23] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:23] DEBUG: Generated='red' vs Expected='red yellow blue'
[14:07:23] DEBUG: Overlap=1, Precision=1.000, Recall=0.333
[14:07:23] DEBUG: F1=0.500, EM=0.0, Overlap=0.333
[14:07:23] DEBUG: Generated='france' vs Expected='france'
[14:07:23] DEBUG: Overlap=1, Precision=1.000, Recall=1.000
[14:07:23] DEBUG: F1=1.000, EM=1.0, Overlap=1.000
[14:07:24] DEBUG: Generated='the 10th and 13th centuries' vs Expected='10th and 11th centuries'
[14:07:24] DEBUG: Overlap=3, Precision=0.600, Recall=0.750
[14:07:24] DEBUG: F1=0.667, EM=0.0, Overlap=0.750
[14:07:24] DEBUG: Generated='scandinavia' vs Expected='denmark, iceland and norway'
[14:07:24] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:24] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:25] DEBUG: Generated='who was the norse leader' vs Expected='rollo'
[14:07:25] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:25] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:26] DEBUG: Generated='the ninth century' vs Expected='10th century'
[14:07:26] DEBUG: Overlap=1, Precision=0.333, Recall=0.500
[14:07:26] DEBUG: F1=0.400, EM=0.0, Overlap=0.500
[14:07:26] DEBUG: Generated='normandy duke of normandy' vs Expected='william the conqueror'
[14:07:26] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:26] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:27] DEBUG: Generated='king charles iii' vs Expected='richard i'
[14:07:27] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:27] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:27] DEBUG: Generated='catholicism' vs Expected='catholic'
[14:07:27] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:27] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:27]   Progress: 20/50 - Recent F1: 0.257
[14:07:28] DEBUG: Generated='norman' vs Expected='viking'
[14:07:28] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:28] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:28] DEBUG: Generated='in 1024' vs Expected='9th century'
[14:07:28] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:28] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:29] DEBUG: Generated='1066' vs Expected='911'
[14:07:29] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:29] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:29] DEBUG: Generated='charles the simple' vs Expected='king charles iii'
[14:07:29] DEBUG: Overlap=1, Precision=0.333, Recall=0.333
[14:07:29] DEBUG: F1=0.333, EM=0.0, Overlap=0.333
[14:07:30] DEBUG: Generated='tennessee river' vs Expected='seine'
[14:07:30] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:30] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:31] DEBUG: Generated='the normans' vs Expected='rollo'
[14:07:31] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:31] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:31] DEBUG: Generated='normanism' vs Expected='catholicism'
[14:07:31] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:31] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:31] DEBUG: Generated='normandy' vs Expected='north'
[14:07:31] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:31] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:32] DEBUG: Generated='foodstuffs' vs Expected='fighting horsemen'
[14:07:32] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:32] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:32] DEBUG: Generated='the byzantine empire' vs Expected='seljuk turks'
[14:07:32] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:32] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:32]   Progress: 30/50 - Recent F1: 0.033
[14:07:33] DEBUG: Generated='during the byzantine war' vs Expected='1050s'
[14:07:33] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:33] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:33] DEBUG: Generated='2003' vs Expected='1060s'
[14:07:33] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:33] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:34] DEBUG: Generated='ask the question' vs Expected='alexius komnenos'
[14:07:34] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:34] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:34] DEBUG: Generated='neuschwanstein castle' vs Expected='afranji'
[14:07:34] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:34] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:35] DEBUG: Generated='roosevelt' vs Expected='oursel'
[14:07:35] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:35] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:35] DEBUG: Generated='turkey' vs Expected='turkish forces'
[14:07:35] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:35] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:36] DEBUG: Generated='normandy' vs Expected='norman mercenary'
[14:07:36] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:36] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:36] DEBUG: Generated='( last ) frederick iii' vs Expected='robert guiscard'
[14:07:36] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:36] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:37] DEBUG: Generated='180 bc' vs Expected='1082'
[14:07:37] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:37] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:37] DEBUG: Generated='about a million men' vs Expected='30,000'
[14:07:37] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:37] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:37]   Progress: 40/50 - Recent F1: 0.000
[14:07:38] DEBUG: Generated='in jaffa' vs Expected='deabolis'
[14:07:38] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:38] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:39] DEBUG: Generated='robert's son' vs Expected='bohemond'
[14:07:39] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:39] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:39] DEBUG: Generated='river sita' vs Expected='deabolis'
[14:07:39] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:39] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:39] DEBUG: Generated='2018' vs Expected='1185'
[14:07:39] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:39] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:40] DEBUG: Generated='naval air station' vs Expected='dyrrachium'
[14:07:40] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:40] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:40] DEBUG: Generated='the fundamental question' vs Expected='the adriatic'
[14:07:40] DEBUG: Overlap=1, Precision=0.333, Recall=0.500
[14:07:40] DEBUG: F1=0.400, EM=0.0, Overlap=0.500
[14:07:41] DEBUG: Generated='mr. knightley' vs Expected='king ethelred ii'
[14:07:41] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:41] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:41] DEBUG: Generated='ellen' vs Expected='duke richard ii'
[14:07:41] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:41] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:42] DEBUG: Generated='to return to england' vs Expected='normandy'
[14:07:42] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:42] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:42] DEBUG: Generated='what turns you on?' vs Expected='sweyn forkbeard'
[14:07:42] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:42] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:42]   Progress: 50/50 - Recent F1: 0.040
[14:07:42]    context_guided completed: F1=0.109, EM=0.040
[14:07:42] 
ðŸ”„ Testing template: confident_direct
[14:07:43] DEBUG: Generated='paris' vs Expected='paris'
[14:07:43] DEBUG: Overlap=1, Precision=1.000, Recall=1.000
[14:07:43] DEBUG: F1=1.000, EM=1.0, Overlap=1.000
[14:07:43] DEBUG: Generated='william shakespeare' vs Expected='william shakespeare'
[14:07:43] DEBUG: Overlap=2, Precision=1.000, Recall=1.000
[14:07:43] DEBUG: F1=1.000, EM=1.0, Overlap=1.000
[14:07:44] DEBUG: Generated='what turns you on?' vs Expected='4'
[14:07:44] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:44] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:44] DEBUG: Generated='to convert light energy into chemical energy' vs Expected='process where plants make food from sunlight'
[14:07:44] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:44] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:45] DEBUG: Generated='what turns you on?' vs Expected='they process information using electrical circuits'
[14:07:45] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:45] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:45] DEBUG: Generated='red' vs Expected='red blue green'
[14:07:45] DEBUG: Overlap=1, Precision=1.000, Recall=0.333
[14:07:45] DEBUG: F1=0.500, EM=0.0, Overlap=0.333
[14:07:46] DEBUG: Generated='rodents' vs Expected='cat dog'
[14:07:46] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:46] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:46] DEBUG: Generated='why is water important?' vs Expected='essential for life and survival'
[14:07:46] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:46] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:46] DEBUG: Generated='chlorophyll' vs Expected='chlorophyll'
[14:07:46] DEBUG: Overlap=1, Precision=1.000, Recall=1.000
[14:07:46] DEBUG: F1=1.000, EM=1.0, Overlap=1.000
[14:07:47] DEBUG: Generated='is the earth round' vs Expected='yes'
[14:07:47] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:47] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:47]   Progress: 10/50 - Recent F1: 0.350
[14:07:47] DEBUG: Generated='' vs Expected='yes'
[14:07:47] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:47] DEBUG: Generated='red' vs Expected='red yellow blue'
[14:07:47] DEBUG: Overlap=1, Precision=1.000, Recall=0.333
[14:07:47] DEBUG: F1=0.500, EM=0.0, Overlap=0.333
[14:07:48] DEBUG: Generated='france' vs Expected='france'
[14:07:48] DEBUG: Overlap=1, Precision=1.000, Recall=1.000
[14:07:48] DEBUG: F1=1.000, EM=1.0, Overlap=1.000
[14:07:49] DEBUG: Generated='10th century -- 15th century' vs Expected='10th and 11th centuries'
[14:07:49] DEBUG: Overlap=1, Precision=0.250, Recall=0.250
[14:07:49] DEBUG: F1=0.250, EM=0.0, Overlap=0.250
[14:07:49] DEBUG: Generated='iceland' vs Expected='denmark, iceland and norway'
[14:07:49] DEBUG: Overlap=1, Precision=1.000, Recall=0.250
[14:07:49] DEBUG: F1=0.400, EM=0.0, Overlap=0.250
[14:07:50] DEBUG: Generated='who was the norse leader' vs Expected='rollo'
[14:07:50] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:50] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:50] DEBUG: Generated='the ninth century' vs Expected='10th century'
[14:07:50] DEBUG: Overlap=1, Precision=0.333, Recall=0.500
[14:07:50] DEBUG: F1=0.400, EM=0.0, Overlap=0.500
[14:07:51] DEBUG: Generated='william' vs Expected='william the conqueror'
[14:07:51] DEBUG: Overlap=1, Precision=1.000, Recall=0.333
[14:07:51] DEBUG: F1=0.500, EM=0.0, Overlap=0.333
[14:07:52] DEBUG: Generated='the king of england' vs Expected='richard i'
[14:07:52] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:52] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:52] DEBUG: Generated='catholicism' vs Expected='catholic'
[14:07:52] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:52] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:52]   Progress: 20/50 - Recent F1: 0.305
[14:07:53] DEBUG: Generated='north' vs Expected='viking'
[14:07:53] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:53] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:53] DEBUG: Generated='in 1024' vs Expected='9th century'
[14:07:53] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:53] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:54] DEBUG: Generated='1066' vs Expected='911'
[14:07:54] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:54] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:54] DEBUG: Generated='charles the simple' vs Expected='king charles iii'
[14:07:54] DEBUG: Overlap=1, Precision=0.333, Recall=0.333
[14:07:54] DEBUG: F1=0.333, EM=0.0, Overlap=0.333
[14:07:55] DEBUG: Generated='river of british columbia' vs Expected='seine'
[14:07:55] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:55] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:55] DEBUG: Generated='the normans' vs Expected='rollo'
[14:07:55] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:55] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:56] DEBUG: Generated='islam' vs Expected='catholicism'
[14:07:56] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:56] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:57] DEBUG: Generated='normandy' vs Expected='north'
[14:07:57] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:57] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:57] DEBUG: Generated='cloth' vs Expected='fighting horsemen'
[14:07:57] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:57] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:57] DEBUG: Generated='byzantine empire' vs Expected='seljuk turks'
[14:07:57] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:57] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:57]   Progress: 30/50 - Recent F1: 0.033
[14:07:58] DEBUG: Generated='during the byzantine war' vs Expected='1050s'
[14:07:58] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:58] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:59] DEBUG: Generated='2003' vs Expected='1060s'
[14:07:59] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:59] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:07:59] DEBUG: Generated='oliver cromwell' vs Expected='alexius komnenos'
[14:07:59] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:07:59] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:00] DEBUG: Generated='chÃ¢teau paris' vs Expected='afranji'
[14:08:00] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:00] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:01] DEBUG: Generated='theudebert i' vs Expected='oursel'
[14:08:01] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:01] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:01] DEBUG: Generated='turkey' vs Expected='turkish forces'
[14:08:01] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:01] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:02] DEBUG: Generated='answers the question' vs Expected='norman mercenary'
[14:08:02] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:02] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:02] DEBUG: Generated='tobey' vs Expected='robert guiscard'
[14:08:02] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:02] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:02] DEBUG: Generated='2011' vs Expected='1082'
[14:08:02] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:02] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:03] DEBUG: Generated='350,000 and 150,000' vs Expected='30,000'
[14:08:03] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:03] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:03]   Progress: 40/50 - Recent F1: 0.000
[14:08:03] DEBUG: Generated='constantinople' vs Expected='deabolis'
[14:08:03] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:03] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:04] DEBUG: Generated='steffon' vs Expected='bohemond'
[14:08:04] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:04] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:05] DEBUG: Generated='river sita' vs Expected='deabolis'
[14:08:05] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:05] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:05] DEBUG: Generated='2014' vs Expected='1185'
[14:08:05] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:05] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:05] DEBUG: Generated='guantanamo bay' vs Expected='dyrrachium'
[14:08:05] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:05] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:06] DEBUG: Generated='north america' vs Expected='the adriatic'
[14:08:06] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:06] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:07] DEBUG: Generated='matt willis' vs Expected='king ethelred ii'
[14:08:07] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:07] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:07] DEBUG: Generated='elliot reeve' vs Expected='duke richard ii'
[14:08:07] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:07] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:08] DEBUG: Generated='to return to england' vs Expected='normandy'
[14:08:08] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:08] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:08] DEBUG: Generated='the old man' vs Expected='sweyn forkbeard'
[14:08:08] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:08] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:08]   Progress: 50/50 - Recent F1: 0.000
[14:08:08]    confident_direct completed: F1=0.138, EM=0.080
[14:08:08] 
ðŸ”„ Testing template: structured_response
[14:08:08] DEBUG: Generated='paris' vs Expected='paris'
[14:08:08] DEBUG: Overlap=1, Precision=1.000, Recall=1.000
[14:08:08] DEBUG: F1=1.000, EM=1.0, Overlap=1.000
[14:08:09] DEBUG: Generated='william shakespeare' vs Expected='william shakespeare'
[14:08:09] DEBUG: Overlap=2, Precision=1.000, Recall=1.000
[14:08:09] DEBUG: F1=1.000, EM=1.0, Overlap=1.000
[14:08:09] DEBUG: Generated='the binary interpretation of the numbers' vs Expected='4'
[14:08:09] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:09] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:10] DEBUG: Generated='what turns you on?' vs Expected='process where plants make food from sunlight'
[14:08:10] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:10] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:11] DEBUG: Generated='what turns you on?' vs Expected='they process information using electrical circuits'
[14:08:11] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:11] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:11] DEBUG: Generated='red' vs Expected='red blue green'
[14:08:11] DEBUG: Overlap=1, Precision=1.000, Recall=0.333
[14:08:11] DEBUG: F1=0.500, EM=0.0, Overlap=0.333
[14:08:11] DEBUG: Generated='cat' vs Expected='cat dog'
[14:08:11] DEBUG: Overlap=1, Precision=1.000, Recall=0.500
[14:08:11] DEBUG: F1=0.667, EM=0.0, Overlap=0.500
[14:08:12] DEBUG: Generated='water infinity' vs Expected='essential for life and survival'
[14:08:12] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:12] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:12] DEBUG: Generated='what turns you on' vs Expected='chlorophyll'
[14:08:12] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:12] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:13] DEBUG: Generated='the question' vs Expected='yes'
[14:08:13] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:13] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:13]   Progress: 10/50 - Recent F1: 0.317
[14:08:13] DEBUG: Generated='' vs Expected='yes'
[14:08:13] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:13] DEBUG: Generated='blue' vs Expected='red yellow blue'
[14:08:13] DEBUG: Overlap=1, Precision=1.000, Recall=0.333
[14:08:13] DEBUG: F1=0.500, EM=0.0, Overlap=0.333
[14:08:14] DEBUG: Generated='france' vs Expected='france'
[14:08:14] DEBUG: Overlap=1, Precision=1.000, Recall=1.000
[14:08:14] DEBUG: F1=1.000, EM=1.0, Overlap=1.000
[14:08:15] DEBUG: Generated='between the 10th and 13th centuries' vs Expected='10th and 11th centuries'
[14:08:15] DEBUG: Overlap=3, Precision=0.500, Recall=0.750
[14:08:15] DEBUG: F1=0.600, EM=0.0, Overlap=0.750
[14:08:15] DEBUG: Generated='iceland' vs Expected='denmark, iceland and norway'
[14:08:15] DEBUG: Overlap=1, Precision=1.000, Recall=0.250
[14:08:15] DEBUG: F1=0.400, EM=0.0, Overlap=0.250
[14:08:15] DEBUG: Generated='the norse leader' vs Expected='rollo'
[14:08:15] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:15] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:16] DEBUG: Generated='the european renaissance' vs Expected='10th century'
[14:08:16] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:16] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:17] DEBUG: Generated='the duke of normandy' vs Expected='william the conqueror'
[14:08:17] DEBUG: Overlap=1, Precision=0.250, Recall=0.333
[14:08:17] DEBUG: F1=0.286, EM=0.0, Overlap=0.333
[14:08:17] DEBUG: Generated='king' vs Expected='richard i'
[14:08:17] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:17] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:18] DEBUG: Generated='islam' vs Expected='catholic'
[14:08:18] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:18] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:18]   Progress: 20/50 - Recent F1: 0.279
[14:08:18] DEBUG: Generated='what turns you on?' vs Expected='viking'
[14:08:18] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:18] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:19] DEBUG: Generated='in 1024' vs Expected='9th century'
[14:08:19] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:19] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:19] DEBUG: Generated='987' vs Expected='911'
[14:08:19] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:19] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:20] DEBUG: Generated='the franks' vs Expected='king charles iii'
[14:08:20] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:20] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:20] DEBUG: Generated='the rio de janeiro' vs Expected='seine'
[14:08:20] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:20] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:21] DEBUG: Generated='the question' vs Expected='rollo'
[14:08:21] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:21] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:21] DEBUG: Generated='islam' vs Expected='catholicism'
[14:08:21] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:21] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:22] DEBUG: Generated='northern france' vs Expected='north'
[14:08:22] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:22] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:22] DEBUG: Generated='foodstuffs' vs Expected='fighting horsemen'
[14:08:22] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:22] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:23] DEBUG: Generated='byzantine empire' vs Expected='seljuk turks'
[14:08:23] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:23] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:23]   Progress: 30/50 - Recent F1: 0.000
[14:08:23] DEBUG: Generated='1984 -- 86' vs Expected='1050s'
[14:08:23] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:23] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:23] DEBUG: Generated='2017' vs Expected='1060s'
[14:08:23] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:23] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:24] DEBUG: Generated='his idea of kingship' vs Expected='alexius komnenos'
[14:08:24] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:24] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:24] DEBUG: Generated='the classic roman republic' vs Expected='afranji'
[14:08:24] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:24] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:25] DEBUG: Generated='charles martel' vs Expected='oursel'
[14:08:25] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:25] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:25] DEBUG: Generated='turkey' vs Expected='turkish forces'
[14:08:25] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:25] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:26] DEBUG: Generated='norman origin' vs Expected='norman mercenary'
[14:08:26] DEBUG: Overlap=1, Precision=0.500, Recall=0.500
[14:08:26] DEBUG: F1=0.500, EM=0.0, Overlap=0.500
[14:08:26] DEBUG: Generated='( last ) frederick iii' vs Expected='robert guiscard'
[14:08:26] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:26] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:27] DEBUG: Generated='what turns you on?' vs Expected='1082'
[14:08:27] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:27] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:27] DEBUG: Generated='3,000 infantry and 300 horsemen' vs Expected='30,000'
[14:08:27] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:27] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:27]   Progress: 40/50 - Recent F1: 0.050
[14:08:28] DEBUG: Generated='constantinople' vs Expected='deabolis'
[14:08:28] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:28] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:28] DEBUG: Generated='robert's son' vs Expected='bohemond'
[14:08:28] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:28] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:29] DEBUG: Generated='river sitka' vs Expected='deabolis'
[14:08:29] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:29] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:29] DEBUG: Generated='the battle of dyrrachium' vs Expected='1185'
[14:08:29] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:29] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:30] DEBUG: Generated='naval base or fort' vs Expected='dyrrachium'
[14:08:30] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:30] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:30] DEBUG: Generated='the fundamental question' vs Expected='the adriatic'
[14:08:30] DEBUG: Overlap=1, Precision=0.333, Recall=0.500
[14:08:30] DEBUG: F1=0.400, EM=0.0, Overlap=0.500
[14:08:31] DEBUG: Generated='the question' vs Expected='king ethelred ii'
[14:08:31] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:31] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:31] DEBUG: Generated='the fundamental question' vs Expected='duke richard ii'
[14:08:31] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:31] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:32] DEBUG: Generated='the king's question' vs Expected='normandy'
[14:08:32] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:32] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:32] DEBUG: Generated='ethelred' vs Expected='sweyn forkbeard'
[14:08:32] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:32] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:32]   Progress: 50/50 - Recent F1: 0.040
[14:08:32]    structured_response completed: F1=0.137, EM=0.060
[14:08:32] 
ðŸ”„ Testing template: basic
[14:08:32] DEBUG: Generated='paris' vs Expected='paris'
[14:08:32] DEBUG: Overlap=1, Precision=1.000, Recall=1.000
[14:08:32] DEBUG: F1=1.000, EM=1.0, Overlap=1.000
[14:08:33] DEBUG: Generated='william shakespeare' vs Expected='william shakespeare'
[14:08:33] DEBUG: Overlap=2, Precision=1.000, Recall=1.000
[14:08:33] DEBUG: F1=1.000, EM=1.0, Overlap=1.000
[14:08:33] DEBUG: Generated='factorials n!' vs Expected='4'
[14:08:33] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:33] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:34] DEBUG: Generated='to convert light energy into chemical energy' vs Expected='process where plants make food from sunlight'
[14:08:34] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:34] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:34] DEBUG: Generated='numerical interpretation of numbers' vs Expected='they process information using electrical circuits'
[14:08:34] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:34] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:35] DEBUG: Generated='white' vs Expected='red blue green'
[14:08:35] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:35] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:35] DEBUG: Generated='amphibians' vs Expected='cat dog'
[14:08:35] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:35] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:35] DEBUG: Generated='all living things require water' vs Expected='essential for life and survival'
[14:08:35] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:35] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:36] DEBUG: Generated='chlorophyll' vs Expected='chlorophyll'
[14:08:36] DEBUG: Overlap=1, Precision=1.000, Recall=1.000
[14:08:36] DEBUG: F1=1.000, EM=1.0, Overlap=1.000
[14:08:36] DEBUG: Generated='ellipse' vs Expected='yes'
[14:08:36] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:36] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:36]   Progress: 10/50 - Recent F1: 0.300
[14:08:37] DEBUG: Generated='bird flight' vs Expected='yes'
[14:08:37] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:37] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:37] DEBUG: Generated='blue' vs Expected='red yellow blue'
[14:08:37] DEBUG: Overlap=1, Precision=1.000, Recall=0.333
[14:08:37] DEBUG: F1=0.500, EM=0.0, Overlap=0.333
[14:08:38] DEBUG: Generated='france' vs Expected='france'
[14:08:38] DEBUG: Overlap=1, Precision=1.000, Recall=1.000
[14:08:38] DEBUG: F1=1.000, EM=1.0, Overlap=1.000
[14:08:38] DEBUG: Generated='9th century -- 9th century' vs Expected='10th and 11th centuries'
[14:08:38] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:38] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:39] DEBUG: Generated='sweden' vs Expected='denmark, iceland and norway'
[14:08:39] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:39] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:39] DEBUG: Generated='cnut' vs Expected='rollo'
[14:08:39] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:39] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:40] DEBUG: Generated='the ninth century' vs Expected='10th century'
[14:08:40] DEBUG: Overlap=1, Precision=0.333, Recall=0.500
[14:08:40] DEBUG: F1=0.400, EM=0.0, Overlap=0.500
[14:08:40] DEBUG: Generated='william' vs Expected='william the conqueror'
[14:08:40] DEBUG: Overlap=1, Precision=1.000, Recall=0.333
[14:08:40] DEBUG: F1=0.500, EM=0.0, Overlap=0.333
[14:08:41] DEBUG: Generated='king charles iii of west francia' vs Expected='richard i'
[14:08:41] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:41] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:41] DEBUG: Generated='catholicism' vs Expected='catholic'
[14:08:41] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:41] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:41]   Progress: 20/50 - Recent F1: 0.240
[14:08:41] DEBUG: Generated='north' vs Expected='viking'
[14:08:41] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:41] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:42] DEBUG: Generated='1024' vs Expected='9th century'
[14:08:42] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:42] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:42] DEBUG: Generated='1066' vs Expected='911'
[14:08:42] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:42] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:43] DEBUG: Generated='charles the simple' vs Expected='king charles iii'
[14:08:43] DEBUG: Overlap=1, Precision=0.333, Recall=0.333
[14:08:43] DEBUG: F1=0.333, EM=0.0, Overlap=0.333
[14:08:43] DEBUG: Generated='elbe' vs Expected='seine'
[14:08:43] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:43] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:43] DEBUG: Generated='the byzantines' vs Expected='rollo'
[14:08:43] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:43] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:44] DEBUG: Generated='catholicism' vs Expected='catholicism'
[14:08:44] DEBUG: Overlap=1, Precision=1.000, Recall=1.000
[14:08:44] DEBUG: F1=1.000, EM=1.0, Overlap=1.000
[14:08:44] DEBUG: Generated='west france' vs Expected='north'
[14:08:44] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:44] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:45] DEBUG: Generated='cloth' vs Expected='fighting horsemen'
[14:08:45] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:45] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:45] DEBUG: Generated='hohenstaufen' vs Expected='seljuk turks'
[14:08:45] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:45] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:45]   Progress: 30/50 - Recent F1: 0.133
[14:08:46] DEBUG: Generated='1984 -- 86' vs Expected='1050s'
[14:08:46] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:46] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:46] DEBUG: Generated='862' vs Expected='1060s'
[14:08:46] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:46] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:47] DEBUG: Generated='henshaw' vs Expected='alexius komnenos'
[14:08:47] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:47] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:47] DEBUG: Generated='neath castle' vs Expected='afranji'
[14:08:47] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:47] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:48] DEBUG: Generated='theudebert i' vs Expected='oursel'
[14:08:48] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:48] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:48] DEBUG: Generated='turkey' vs Expected='turkish forces'
[14:08:48] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:48] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:48] DEBUG: Generated='english' vs Expected='norman mercenary'
[14:08:48] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:48] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:49] DEBUG: Generated='( last ) frederick iii' vs Expected='robert guiscard'
[14:08:49] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:49] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:50] DEBUG: Generated='10th century' vs Expected='1082'
[14:08:50] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:50] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:50] DEBUG: Generated='1,000,000' vs Expected='30,000'
[14:08:50] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:50] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:50]   Progress: 40/50 - Recent F1: 0.000
[14:08:51] DEBUG: Generated='constantinople' vs Expected='deabolis'
[14:08:51] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:51] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:51] DEBUG: Generated='steffon' vs Expected='bohemond'
[14:08:51] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:51] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:52] DEBUG: Generated='river irwell' vs Expected='deabolis'
[14:08:52] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:52] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:52] DEBUG: Generated='october 1174' vs Expected='1185'
[14:08:52] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:52] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:52] DEBUG: Generated='guantanamo bay naval base' vs Expected='dyrrachium'
[14:08:52] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:52] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:53] DEBUG: Generated='canada' vs Expected='the adriatic'
[14:08:53] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:53] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:53] DEBUG: Generated='will arnett' vs Expected='king ethelred ii'
[14:08:53] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:53] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:54] DEBUG: Generated='bradley spencer' vs Expected='duke richard ii'
[14:08:54] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:54] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:54] DEBUG: Generated='fled to be with ethelred' vs Expected='normandy'
[14:08:54] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:54] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:55] DEBUG: Generated='howard' vs Expected='sweyn forkbeard'
[14:08:55] DEBUG: Overlap=0, Precision=0.000, Recall=0.000
[14:08:55] DEBUG: F1=0.000, EM=0.0, Overlap=0.000
[14:08:55]   Progress: 50/50 - Recent F1: 0.000
[14:08:55]    basic completed: F1=0.135, EM=0.100
[14:08:55] 
ðŸŽ‰ Experiment completed! Total results: 350
[14:08:55] 
ðŸ” ANALYZING RESULTS...
[14:08:55] 
ðŸ† TEMPLATE PERFORMANCE RANKING:
[14:08:55] --------------------------------------------------------------------------------
[14:08:55] Template             F1 Score   EM Score   Samples  Improvement 
[14:08:55] --------------------------------------------------------------------------------
[14:08:55] confident_direct     0.138     0.080     50       ++2.2%      
[14:08:55] structured_response  0.137     0.060     50       ++1.8%      
[14:08:55] basic                0.135     0.100     50       BASELINE    
[14:08:55] instructional_clear  0.132     0.060     50       +-1.7%      
[14:08:55] context_guided       0.109     0.040     50       +-18.8%     
[14:08:55] knowledge_synthesis  0.084     0.040     50       +-37.4%     
[14:08:55] retrieval_focused    0.000     0.000     50       +-100.0%    
[14:08:55] 
ðŸ“Š SUCCESS ANALYSIS:
[14:08:55]   ðŸ¥‡ Best Template: confident_direct (F1: 0.138)
[14:08:55]   âœ… SUCCESS! Basic template relegated to rank 3
[14:08:55]   ðŸŽ¯ Template engineering shows measurable impact!
[14:08:55] 
ðŸ“‹ SAMPLE RESULTS:
[14:08:55] ======================================================================
[14:08:55] 
ðŸ”¸ Template: confident_direct (Rank 1)
[14:08:55]    Q: What is the capital of France?...
[14:08:55]    Expected: Paris
[14:08:55]    Generated: paris
[14:08:55]    Score: F1=1.000
[14:08:55]    Q: Who wrote Romeo and Juliet?...
[14:08:55]    Expected: William Shakespeare
[14:08:55]    Generated: william shakespeare
[14:08:55]    Score: F1=1.000
[14:08:55] 
ðŸ”¸ Template: structured_response (Rank 2)
[14:08:55]    Q: What is the capital of France?...
[14:08:55]    Expected: Paris
[14:08:55]    Generated: paris
[14:08:55]    Score: F1=1.000
[14:08:55]    Q: Who wrote Romeo and Juliet?...
[14:08:55]    Expected: William Shakespeare
[14:08:55]    Generated: william shakespeare
[14:08:55]    Score: F1=1.000
[14:08:55] 
ðŸ”¸ Template: basic (Rank 3)
[14:08:55]    Q: What is the capital of France?...
[14:08:55]    Expected: Paris
[14:08:55]    Generated: paris
[14:08:55]    Score: F1=1.000
[14:08:55]    Q: Who wrote Romeo and Juliet?...
[14:08:55]    Expected: William Shakespeare
[14:08:55]    Generated: william shakespeare
[14:08:55]    Score: F1=1.000
[14:08:55] 
ðŸŽ‰ TARGETED EXPERIMENT COMPLETED!
